{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical NLP\n",
    "- In the previous section, we read more on cleaning up the data.\n",
    "- But the focus is now is to convert data from unstructured to structured \n",
    "\n",
    "\n",
    "##  TF-IDF:\n",
    "- TF-IDF is a scheme to weigh individual tokens.\n",
    "- This weight is a statistical measure used to evaluate how important a word is to a document in a collection of documents or corpus.\n",
    "- TF-IDF weighs words by the frequency of appearance within a document but penalizes words that appear across many documents.\n",
    "- The concept is that words appearing many times in a single document are likely noteworthy, but they could also just be common words that appear frequently in all documents.\n",
    "\n",
    "## Bow:\n",
    "- The Bag of Words (BoW) model is the simplest form of text representation in numbers.\n",
    "- Like the term itself, we can represent a sentence as a bag of words vector (a string of numbers).\n",
    "- The BoW model retains neither information on the grammar of the sentences nor the ordering of the words in the text.\n",
    "\n",
    "## Comparing TF-IDF and Bow:\n",
    "- Bag of Words just creates a set of vectors containing the count of word occurrences in the document (reviews), while the TF-IDF model contains information on the more important words and the less important ones as well.\n",
    "- Bag of Words vectors is easy to interpret. However, TF-IDF usually performs better in machine learning models.\n",
    "\n",
    "## Disads of Bow Model:\n",
    "- If the new sentences contain new words, then our vocabulary size would increase, and thereby, the length of the vectors would increase too.\n",
    "- Additionally, the vectors would also contain many zeros, thereby resulting in a sparse matrix (which is what we would like to avoid).\n",
    "- We are retaining no information on the grammar of the sentences nor the ordering of the words in the text.\n",
    "\n",
    "## Vader\n",
    "- VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media. \n",
    "- VADER not only tells about the Positivity and Negativity score but also tells us about how positive or negative a sentiment is.\n",
    "\n",
    "\n",
    "# Word representations\n",
    "## Document term matrix (DTM)\n",
    "- A matrix where cols are the words present in the corpus. Where the rows are the documents itself. (note: also Sunil is not equal to sunil in the text, capital letter differ)\n",
    "- What does each cell in the DTM contains:\n",
    "   - count vectorizer: (Bow vectorizer)\n",
    "       - Where each cell contains the event of number of times the word appeared in the document corpus.\n",
    "       - some disadvantages of bow:\n",
    "           - the columns represent the words, but it is not possible to know the order of the words (since they are unigrams). To deal with this, we introduce bi_gram.\n",
    "   - tf-idf vectorizer:\n",
    "       - TF- term frequency (number of occurance of a word/total words) (captures how important a word to a document)\n",
    "       - IDF -  inverse document frequency (log(Num of docs/word in Num of docs))\n",
    "       - and TF-IDF is TFxIDF.\n",
    "\n",
    "\n",
    "# CountVectorizer\n",
    "- A library in scipy, feature_extraction.\n",
    "- scipy.feature_extraction.Countevectorizer.fit does the tokenizing\n",
    "- scipy.featrue_extraction.Countevectorizer.transform makes the document term matrix.\n",
    "\n",
    "# TFIDFCountVectorizer\n",
    "- A library in scipy, feature_extraction.\n",
    "- scipy.feature_extraction.TFIDFCountevectorizer.fit does the tokenizing and build the vocabulary.\n",
    "- scipy.featrue_extraction.TFIDFCountevectorizer.transform makes the document term matrix.\n",
    "- For this a bunch of documents is given.\n",
    "\n",
    "\n",
    "# VADER sentiment analysis\n",
    "- this does not required labelled data\n",
    "- uses tools called TextBlob \n",
    "- vaderSentiment library: SentimentIntensityAnalyzer\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
